<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>OpenCV.js</title>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb" crossorigin="anonymous">
    <style type="text/css">
        /* Start by setting display:none to make this hidden.
   Then we position it in relation to the viewport window
   with position:fixed. Width, height, top and left speak
   for themselves. Background we set to 80% white with
   our animation centered, and no-repeating */
        
        .modal {
            display: none;
            position: fixed;
            z-index: 1000;
            top: 0;
            left: 0;
            height: 100%;
            width: 100%;
            background: rgba( 255, 255, 255, .8) url('http://i.stack.imgur.com/FhHRx.gif') 50% 50% no-repeat;
        }
        /* When the body has the loading class, we turn
   the scrollbar off with overflow:hidden */
        
        body.loading {
            overflow: hidden;
        }
        /* Anytime the body has the loading class, our
   modal element will be visible */
        
        body.loading .modal {
            display: block;
        }
    </style>
</head>

<body>
    <div class="container">
        <div class="jumbotron">
            <h1>OpenCV - Circle Detection</h1>
            <p>This website uses OpenCVJS to detect circles in any uploaded image.</p>
        </div>
        <div class="row">
            <div class="col-sm">
                <div class="card">
                    <div class="card-header">
                        Original video
                    </div>
                    <div class="card-block text-center">
                        <video id="videoInput" width=320 height=240></video>
                    </div>
                    <ul class="list-group list-group-flush">

                        <li class="list-group-item">
                            <button type="button" id="startAndStop" class="btn btn-primary" disabled>Start</button>
                        </li>
                    </ul>
                </div>
                <p class="err" id="errorMessage"></p>
            </div>
            <div class="col-sm">
                <div class="card">
                    <div class="card-header">
                        Drived video
                    </div>
                    <div class="card-block">
                        <canvas id="canvasOutput" width=320 height=240></canvas>
                    </div>
                    <ul class="list-group list-group-flush">
                        <li class="list-group-item">
                            <input type="range" id="hcp1" name="hcp1" min="10" max="255" value="175" step="5">
                            <span id="hcp1lbl">150</span>
                        </li>
                        <li class="list-group-item">
                            <input type="range" id="hcp2" name="hcp2" min="10" max="100" value="75" step="5">
                            <span id="hcp2lbl">40</span>
                        </li>
                    </ul>
                </div>
            </div>

        </div>
    </div>
    <div class="modal"></div>

    <!-- webcam adapter -->
    <script src="https://webrtc.github.io/adapter/adapter-5.0.4.js" type="text/javascript"></script>

    <!-- opencv utils 4 video -->
    <script src="utils.js" type="text/javascript"></script>


    <script type="text/javascript">
        document.body.classList.add("loading");

        let utils = new Utils('errorMessage');

        let streaming = false;
        let videoInput = document.getElementById('videoInput');
        let startAndStop = document.getElementById('startAndStop');
        let canvasOutput = document.getElementById('canvasOutput');
        let canvasContext = canvasOutput.getContext('2d');

        startAndStop.addEventListener('click', () => {
            if (!streaming) {
                utils.clearError();
                utils.startCamera('vga', onVideoStarted, 'videoInput');
            } else {
                utils.stopCamera();
                onVideoStopped();
            }
        });

        function onVideoStarted() {
            streaming = true;
            startAndStop.innerText = 'Stop';
            videoInput.width = videoInput.videoWidth;
            videoInput.height = videoInput.videoHeight;
            startProcessVideo();
        }

        function onVideoStopped() {
            streaming = false;
            canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
            startAndStop.innerText = 'Start';
        }

        function onOpenCvReady() {
            let faceCascadeFile = 'haarcascade_frontalface_default.xml';
            utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
                document.body.classList.remove("loading");
                startAndStop.removeAttribute('disabled');
            });
        }

        // process Video
        let video = document.getElementById('videoInput');
        let src = null; //new cv.Mat(video.height, video.width, cv.CV_8UC4);
        let dst = null; //new cv.Mat(video.height, video.width, cv.CV_8UC4);
        let gray = null; //new cv.Mat();
        let cap = null; //new cv.VideoCapture(video);
        let faces = null; //new cv.RectVector();
        let circles = null; //new cv.Mat();
        let classifier = null; //new cv.CascadeClassifier();

        let hcp1Input = document.getElementById('hcp1');
        let hcp2Input = document.getElementById('hcp2');

        let hcp1 = hcp1Input.valueAsNumber;
        let hcp2 = hcp2Input.valueAsNumber;
        hcp1Input.oninput = function() {
            hcp1 = hcp1Input.valueAsNumber;
            document.getElementById('hcp1lbl').textContent = hcp1;
        };
        hcp2Input.oninput = function() {
            hcp2 = hcp2Input.valueAsNumber;
            document.getElementById('hcp2lbl').textContent = hcp2;
        };

        // load pre-trained classifiers
        //classifier.load('haarcascade_frontalface_default.xml');

        const FPS = 30;

        function processVideo() {
            try {
                if (!streaming) {
                    // clean and stop.
                    src.delete();
                    dst.delete();
                    gray.delete();
                    faces.delete();
                    circles.delete();
                    classifier.delete();
                    return;
                }
                let begin = Date.now();
                // start processing.
                cap.read(src);
                src.copyTo(dst);
                cv.flip(dst, dst, 1);
                cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
                /*
                // detect faces.
                classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
                // draw faces.
                for (let i = 0; i < faces.size(); ++i) {
                    let face = faces.get(i);
                    let point1 = new cv.Point(face.x, face.y);
                    let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                    cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
                }
                */

                let ksize = new cv.Size(3, 3);
                cv.GaussianBlur(gray, gray, ksize, 0, 0, cv.BORDER_DEFAULT);

                cv.HoughCircles(gray, circles, cv.HOUGH_GRADIENT,
                    1, 30, hcp1, hcp2, 0, 0);
                // draw circles
                for (let i = 0; i < circles.cols; ++i) {
                    let x = circles.data32F[i * 3];
                    let y = circles.data32F[i * 3 + 1];
                    let radius = circles.data32F[i * 3 + 2];
                    let center = new cv.Point(x, y);
                    cv.circle(dst, center, radius, [0, 0, 0, 255], 3);
                }

                cv.imshow('canvasOutput', dst);
                // schedule the next one.
                let delay = 1000 / FPS - (Date.now() - begin);
                setTimeout(processVideo, delay);
            } catch (err) {
                utils.printError(err);
            }
        };

        function startProcessVideo() {
            src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
            dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
            gray = new cv.Mat();
            cap = new cv.VideoCapture(video);
            faces = new cv.RectVector();
            circles = new cv.Mat();
            classifier = new cv.CascadeClassifier();

            classifier.load('haarcascade_frontalface_default.xml');
            // schedule the first one.
            setTimeout(processVideo, 0);
        }
    </script>
    <script async src="opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
</body>

</html>